
\section{JavaScript [R]}
Zuerst musste die Entscheidung gefällt werden, ob unser Projekt ein Standalone-Programm sein soll, oder im Browser zu erreichen ist. Weil wir aber wollten, dass es ein
Party-Game werden soll, dass man ohne jeglichen Aufwand sofort mit Freunden spielen kann, haben wir uns für die Browser-Variante entschieden.
Für mich war es eine leichte Entscheidung JavaScript zu verwenden, da die Programmiersprache genau für den Browser geeignet ist, und man damit nicht nur im Frontend, sondern auch im Backend programmieren kann.
\setauthor{Rafetseder Tobias}
\subsection{p5.js / p5.play [R]}
\label{subsection:p5js}
p5.js ist eine open-source JavaScript Library, die für Kreation von Spielen genutzt wird.
p5.play ist eine Library für p5.js, mit der man visuelle Objekte managen kann. Außerdem beinhaltet es Features wie Animation-Support,
Kollisionserkennung, sowie aber auch Funktionen für Maus- und Tastatur-Interaktionen.
Es ist wichtig sich im Hinterkopf zu behalten, dass p5.play für barrierefreies und simples Programmieren gedacht ist, nicht für perfomantes.
Es ist keine eigene Engine, und unterstütz auch keine 3D-Spiele.

\subsubsection{Einbindung}
Der einfachste Weg p5.js einzubinden ist auf ein JavaScript File online zu verweisen.

\begin{lstlisting}
    <script 
    src="https://cdn.jsdelivr.net/npm/p5@1.4.0/lib/p5.js">
    </script>
\end{lstlisting}
Man kann sich aber auch die p5.js Library
lokal downloaden unter \url{https://p5js.org/download/}
Dann muss man nur noch auf das lokale File verweisen.

\begin{lstlisting}
    <script src="../p5.min.js"></script>
\end{lstlisting}

Jedoch muss man das Projekt dann auf einem lokalen Server (z.B. Node.js) hosten.

\subsubsection{Struktur eines p5.js Projekts}
Die Struktur ist sehr simpel. Im Ganzen ist es nur ein \texttt{index.html} File und ein \texttt{sketch.js} File. In dem HTML File bindet man die p5-Library ein, und auch das sketch.js File.

\begin{figure}[H]
    \centering
    \includegraphics[scale=1]{pics/index html.PNG}
    \caption{Aufbau index.html}
\end{figure}

So kann man nun in dem sketch.js File die p5.js Methoden nutzen. Die wichtigsten Methoden sind die Setup- und die Draw-Methode.
Die Setup-Methode wird vor der Draw-Methode aufgerufen um das Spiel zu initialisieren. (Es wird zum Beispiel ein Canvas erstellt).
Wenn diese abgeschlossen ist, wird die Draw-Methode 60 mal in der Sekunde aufgerufen und updatet jedes mal den Bildschirm.

\begin{figure}[H]
    \centering
    \includegraphics[scale=1]{pics/sketch.PNG}
    \caption{Simples sketch.js Beispiel}
\end{figure}

\subsubsection{P5.js vs Processing}
p5.js ähnelt sich sehr stark mit Processing, eine Programmiersprache die man sich wie ein stark vereinfachte Version von Java vorstellen kann.
Der Unterschied liegt darin, dass Java eine Umgebung, basierend auf der Java Programmiersprache ist, während p5.js eine Bibliothek, basierend auf der JavaScript Programmiersprache ist.
Processing ist dafür geeignet, lokale Applikationen zu bauen, hingegen dazu kann p5.js nur im Browser ausgeführt werden.

p5.js ist also kurzgesagt ein direkter JavaScript Port für die Processing Programmiersprache.

Vorteile von p5.js:
\begin{compactitem}
    \item Man kann interaktive Programme entwickeln, die in jedem modernen Browser funktionieren (plattformunabhängig)
    \item Das Programm ist nicht nur lokal auf dem eigenen Gerät, was das Teilen sehr viel leichter macht
    \item Man hat die Option den p5.js Editor im Web zu verwenden: Überhaupt kein Aufwand, um loszuprogrammieren
\end{compactitem}

Nachteile von p5.js:
\begin{compactitem}
    \item Ist langsamer beim Pixel manipulieren
    \item Ist kein Standalone-Programm, d.h. ein Browser wird benötigt
\end{compactitem}

\subsection {Node.js [R]}
Node.js ist eine plattformübergreifende Open-Source-JavaScript-Laufzeitumgebung, mit der Besonderheit, dass sie JavaScript-Code außerhalb eines Webbrowsers ausführen kann
und wurde ursprünglich von Ryan Dahl 2009 entwickelt, einem Software-Entwickler aus San Diego, Kalifornien.
Die Laufzeitumgebung wurde darauf spezialisiert, leicht skalierbare Server zu bauen.

In dem folgenden "Hello World"-Beispiel, können viele Verbindung gleichzeitig behandelt werden. Bei jeder Verbindung wird die Callback-Funktion ausgeführt, aber wenn keine Arbeit zu erledigen ist, schläft Node.js.

\begin{figure}[H]
    \centering
    \includegraphics[scale=1]{pics/node js.PNG}
    \caption{Sehr simpler Node.js Server}
\end{figure}

Man merkt den Unterschied zu den heutzutage weit verbreiteten Concurrency-Modellen, die mit OS-Threads arbeiten. Der Vorteil von Node.js hierbei ist, dass
man sich keine Sorgen über dead-locking machen muss, da fast keine Node.js Funktion direkte I/O Operationen durchführt. Also ist der ganze Prozess so gut wie nie blockiert, ausser
wenn synchrone Methoden der Node.js Standard Library benutzt wird.

\subsubsection{NPM}\label{NPM}
Neben Node an sich, ist NPM (Node Package Manager) das wichtigste Werkzeug für Node Applikationen. Mit NPM können alle Packages, die das Projekt benötigt, gefetched werden.
Es ist möglich, alle Packages einzeln zu fetchen, jedoch benutzt man normalerweise ein package.json File. In diesem File stehen alle Dependencies für jedes JavaScript Package,
das benötigt wird, sowie auch Meta-Daten zu dem Node Projekt. Erstellt wird dieses
in dem man in das Verzeichnis navigiert, in dem man das Projekt haben will und den Befehl \texttt{npm init} ausführt.

\begin{figure}[H]
    \centering
    \includegraphics[scale=1]{pics/package json.PNG}
    \caption{Package.json des Scribble-Fight Backends}
\end{figure}

\subsubsection{Express}
Express ist das am meisten verbreiteteste Node Web Framework und ist auch die Basis für andere Node Web Frameworks. Die Hauptverantwortung
von Express ist das Bereitstellen von Server-Logik wie zum Beispiel das Schreiben von Handlers für Requests mit unterschiedlichen Http Verbs auf unterschiedlichen URL Pfaden.
Man kann Express mit dem Node Package Manager mit \texttt{npm install express} installieren, oder man befindet sich in
einem Verzeichnis mit package.json File bei dem Express als Dependency hinzugefügt wurde, dann reicht \texttt{npm install}

\begin{figure}[H]
    \centering
    \includegraphics[scale=1]{pics/Express.PNG}
    \caption{Simpler Web Server mit Express}
\end{figure}

\subsection{Socket IO [R]}

Socket.IO ist eine Library, die eine bidirektionale Echt-Zeit Verbindung zwischen Server und Client ermöglicht. Es besteht aus
\begin{compactitem}
    \item Einem Node.js Server
    \item Einer JavaScript Client Library (Es bestehen auch einige andere Client Implementationen für Sprachen wie Java, C++, Python, etc.)
\end{compactitem}

Socket.IO funktioniert so, dass der Client, falls möglich, eine WebSocket Verbindung mit dem Server herstellt.
Ist keine Verbindung möglich, setzt der Client einen HTTP long polling Request ab.

\begin{figure}[H]
    \centering
    \includegraphics[scale=1]{pics/SocketIO_client.PNG}
    \caption{Socket.IO Client Beispiel}
\end{figure}

Damit der Server die Verbindung annehmen kann, müssen folgende Kriterien erfüllt sein:
\begin{compactitem}
    \item Der Browser unterstützt WebSocket
    \item Die Verbindung wird nicht von Elementen wie Firewall gestört
\end{compactitem}
Die API ist auf der Server-Seite dem Client sehr ähnlich, man bekommt auch wieder ein \texttt{socket} Objekt, welches von der EventEmitter Klasse von Node.js erbt.

\begin{figure}[H]
    \centering
    \includegraphics[scale=1]{pics/SocketIO_server.PNG}
    \caption{Socket.IO Server Beispiel}
\end{figure}


\subsubsection{Unterschied Socket.IO zu WebSocket}
Socket.IO ist keine WebSocket Implementation. Auch wenn Socket.IO WebSocket als Transportmittel benutzt, werden bei jedem Paket zusätzliche Metadaten angehängt. Das ist auch der Grund, warum
ein Socket.IO Client keine Verbindung mit einem schlichten WebSocket Server herstellen kann, und umgekehrt.
Man kann sich Socket.IO also als einen Wrapper rund um die WebSocket API vorstellen.

\section{Deployment [R]}
Das Scribble-Fight Browser-Game wurde in die Leocloud, ein Cloud-System der HTL-Leonding, unter \url{https://student.cloud.htl-leonding.ac.at/t.rafetseder/scribble-fight/} deployed.
Zuerst wurde mithilfe von der Docker-Technologie ein Docker-Image erstellt und auf die Leocloud hochgeladen. Das Deployment wurde dann mithilfe von Kubernetes umgesetzt.
Was Docker und Kubernetes genau ist, folgt in den nächsten Sektionen.
\subsection{Docker [R]} \label{tech:docker}
Die Software Docker ist eine Technologie zum Containerisieren von Prozessen, die dann unabhängig voneinander und isoliert ausgeführt werden können. Diese isolierte Prozesse nennt man dann Container.
Durch die Unabhängigkeit, die dadurch entsteht, wird die Infrastruktur besser genutzt und auch die Sicherheit bewahrt, die sich aus der Arbeit mit voneinander getrennten System ergibt.
Docker arbeitet mit einem Image-basierten Bereitstellungsmodell. Dieses wird gerne bei Containertools verwendet, da Applikationen mit all deren Dependencies, egal in welcher Umgebung, genutzt werden können.
\begin{compactitem}
    \item Wenn man einmal seine containerisierte Applikation getestet hat, kann man sich sicher sein, dass die Applikation auf jeder anderen Umgebung, auf dem Docker installiert ist, auch funktioniert
    \item Alle Docker Container sind komplett voneinander unabhängig
    \item Falls Skalierung notwendig ist, kann man schnell neue Container erstellen
    \item Im Gegensatz zu virtuellen Maschinen beinhalten Container keine eigenen Operating Systems, deshalb kann man sie schneller erstellen und auch schneller starten
\end{compactitem}

Wichtige Begriffe, die man im Zusammenhang mit Docker kennen sollte:

\begin{compactitem}
    \item Image: Speicherabbild eines Containers
    \item Container: aktive Instanz eines Images
    \item Dockerfile: eine Textdatei, die den Aufbau des Images beschreibt
    \item Registry: Unter Registry versteht man eine Ansammlung gleicher Images mit verschiedenen Tags, meistens Versionen
\end{compactitem}

\subsubsection{Docker Architektur}
Die Docker Architektur ist eine Server-Client Architektur. Der Docker Client kommuniziert mit dem Docker Daemon, der dann Docker Container z.B. baut und ausführt.
Dieser Docker Daemon kann lokal installiert sein, aber der Client kann sich auch mit einem Daemon Remote verbinden.

\begin{figure}[H]
    \centering
    \includegraphics[scale=0.6]{pics/docker architecture.PNG}
    \caption{Veranschaulichung Docker Architektur}
\end{figure}


\subsection{Kubernetes [R]}
Kubernetes ist Open-Source-Plattform, die dafür genutzt wird, containerisierte Applikationen und Services zu verwalten. Es managed die Computer-, Netzwerk und Speicherinfrastruktur von Containern.
Das Kubernetes-Projekt ist 2014 als Open-Source Projekt in die Welt gerufen worden.

Kubernetes hat mehrere Funktionen, zum Beispiel ist Kubernetes:
\begin{compactitem}
    \item eine Containerplattform
    \item eine Microservices-Plattform
    \item eine Cloud-Plattform
\end{compactitem}

In dieser Diplomarbeit wird Kubernetes benutzt, um ein mit Docker gebautes Images des Scribble-Fight Browsergames auf ein Cloudsystem zu deployen. Näheres zur Umsetzung findet man \url{hier}

\newpage
\section{Python [H]}
Diese Programmiersprache, welche nach der Britischen comedy Serie ``Monty Python'' benannt ist,
fand in unserer Arbeit zwei Haupteinsatzgebiete. \\
Erstens, zur Erkennung des Blatt Papiers und der Umwandlung der Zeichnung in eine spielbare Map
und zweitens um die Künstliche Intelligenz zu erschaffen. \\
Die kostenlosen Bibliotheken, welche wir dabei in Verwendung haben, werden im folgenden gelistet und näher
erklärt.
\setauthor{Himmetsberger Jonas}

\subsection{Flask [H]}
Flask ist das am wohl häufigste verwendete Python Web-Framework. Somit gibt es viele Tutorials,
Tools und Bibliotheken. Diese sind sehr gut bis gut dokumentiert und teilweise geprüft.
Aus diesen Gründen haben wir den Teil der Bild- und Maperkennung, welche
als Webanwendung funktioniert, mittels Flask umgesetzt. In Kombination mit Flask-SocketIO werden Bilder von der Webcam
in Echtzeit direkt an den Server geschickt, welcher dann via OpenCV2 Informationen aus dem Bild
generiert. Genau wie bei SocketIO in JavaScript, agiert Flask-SocketIO als bidirektionale
Kommunikation zwischen Server und Client. Die extrem geringe Latenzzeit, welche dabei auftritt,
ist wichtig um eine flüssige Verarbeitung der Bilder zu gewährleisten.

\subsection{OpenCV2 [H]}
Open ``Computer Vision'' (CV) wurde in unserem Kontext als Python Bibliothek verwendet. OpenCV verfügt über eine
breitgefächerte Auswahl an Bildverarbeitungs-Algorithmen.
Folgende wurden bei der Maperkennung eingesetzt:
\begin{compactitem}
    \item Resizing
    \item Farbraumkonvertierung
    \item Weichzeichnung
    \begin{compactitem}
        \item Median-Blur
        \item Gaussian-Blur
    \end{compactitem}
    \item adaptive Schwellenwertbildung von Pixelwerten
    \item Konvertierung eines Zahlen Arrays in eine ``.png'' datei
\end{compactitem}
Auf die Funktionsweise dieser Algorithmen wird im Folgenden (\ref{maai:alogs}) genauer eingegangen.
\\
Um zum Beispiel ein beliebiges Bild unscharf zu zeichnen würde man so vorgehen:
\\

\begin{lstlisting}[language=Python,caption=OpenCV Demo,label=lst:tech:gaussianBlur]
    # Dieses kurze Programm soll ein Bild in Python mittels Open Computer Vision weichzeichnen
    
    # Importieren der gebrauchten Bibliothek
    import cv2
    import numpy
    
    # Bild einlesen
    source = cv2.imread('./Pfad/zum/Bild.png', cv2.IMREAD_UNCHANGED)
    
    # Das Quell-Bild wird nun unscharf gezeichnet
    destination = cv2.GaussianBlur(source,(5,5),cv2.BORDER_DEFAULT)

    # Anzeigen von dem Quellbild und dem bearbeiteten Bild 
    cv2.imshow('Weichzeichnung',numpy.hstack((source, destination)))

    # warten, bis eine Taste gedrueckt wurde
    cv2.waitKey(0) 

    # Alle Fenster, welche die Bilder anzeigen, werden geschlossen
    cv2.destroyAllWindows() 
\end{lstlisting}

\subsection{PIL [H]}
PIL (Python Image Library) ist, wie Flask und OpenCV2, eine kostenlose Zusatzbibliothek für Python.
PIL wird verwendet um Bilder zu speichern und zu pixel zu manipulieren. Dabei unterstützt PIL diese
Dateiformate: PPM, PNG, JPEG, GIF, TIFF, und BMP. Pixel manipulation bedeutet, dass jeder Pixel auf einem
Input Bild angepasst werden kann. Beispiele hierfür sind zum Beispiel das Aufhellen oder Abdunkeln von
Bildern oder das Anpassen der Sättigung. Auch Kontrast- oder Schärfeeinstellungen können mit
Pixelmanipulation erzielt werden. Dafür werden meistens Matrizen und/oder Formeln pro Pixel verwendet um
deren Farbwerte anzupassen
\\



\begin{lstlisting}[language=Python,caption=PIL Demo,label=lst:tech:PIL]
    # verwendete Klassen der Bibliothek einbinden
    from PIL import Image, ImageFilter  

    source = Image.open("file.ppm") # Load an image from the file system.
    destination = source.filter(ImageFilter.BLUR) # Blur the image.

    # Display both images.
    original_image.show() 
    destination.show()
\end{lstlisting}



\subsection{TensorFlow und Keras [H]}
TensorFlow ist eine Python Bibliothek, welche beim erstellen von Projekten, welche maschinelles Lernen
in irgend einer Art und Weise eingebunden haben, extrem unterstütz.
Wie der Name schon vermuten lässt, basiert TensorFlow auf zwei Grundlagen: Tensoren und Graphen (Flow
vom Wort dataflow). \\
Tensoren sind besser bekannt als Skalare, Vektoren oder Matrizen. Tensoren sind also
null-, ein- oder mehrdimensionale Daten-Tupel.
TensorFlow bietet alles von on der effizienten Ausführung von
Befehlen auf der CPU, oder GPU, über der Skalierung von Berechnungen auf viele Endgeräte bis hin
zur Visualisierung der gelernten Daten mittels dem sogenannten ``TensorBoard''. TensorFlow ist also ein
sehr mächtiges Framework, das viele Möglichkeiten bietet, künstliche Intelligenzen zu trainieren und
analysieren.\\
Jedoch ist die Benutzerfreundlichkeit von TensorFlow sehr eingeschränkt. Viele Entwickler empfanden
es als ungeeignet für schnelles Prototyping und verwendeten daher das auf TensorFlow basierende Keras. \\
Keras verwendet standardmäßig die GPU zum ausführen von Code und is somit um einiges schneller als TensorFlow.
In dieser Diplomarbeit wurden zwei der von TensorFlow (Stable-Baselines3) bereits vorgefertigten Algorithmen,
namens ``A2C'' und ``PPO'', verwendet um die KI zu trainieren. Auf die Auswertung wird im Kapitel \ref{maai:scribblefightki} näher
eingegangen. Die Logik hinter der Künstlichen Intelligenz
wurde mittels OpenAI Gym implementiert.

\subsection{OpenAI Gym [H]}
OpenAI Gym ist ein Toolkit, mit welchem das Erlernen und Erstellen von reinforcement learning Algorithmen
sehr leicht fällt. Da viele Menschen nicht wissen, was ``reinforcement learning'' ist, wird es im folgenden
kurz erläutert.

\subsubsection{Reinforcement Learning[H]}
Reinforcement learning bedeutet auf deutsch so viel wie bestärkendes Lernen oder verstärkendes Lernen.
Diese Art und Weise zu lernen ist der, wie ein Lebewesen mit einem biologischen Gehirn
lernt, am ähnlichsten.
Dabei basiert es auf folgendem Konzept: \\
Ein Agent, welcher etwas erlernen soll, wird in eine ihm unbekannte Umwelt gesetzt. Dieser kennt nicht mehr
als seinen eigenen Zustand und welche Aktionen er ausführen kann. Bewegt sich diese Entität nun in der
Umwelt, so passieren ihm Dinge. Diese können nach einer Observation entweder zu einer negative (-) oder einer
positive (+) Belohnung führen. Das einzige Ziel des Agenten besteht nun darin sein Tun so anzupassen, dass
er so viel und so
effizient wie möglich an diese Belohnung gelangt. Folgende Grafik erläutert das Beispiel an einem Hund,
welcher lernen soll einen Stecken zu apportieren.

\begin{figure}[H]
    \centering
    \includegraphics[scale=0.6]{pics/reinforcementLearningConcept.png}
    \caption{Veranschaulichung bestärkendes Lernen}
\end{figure}

OpenAI Gym hat also einen mehr oder weniger vorgegebenen Bauplan, und vorgegebene Regeln, nach welchen man
so eine Künstliche Intelligenz aufbauen muss. \\
Weitere, weit verbreitete Formen von machine learning sind supervised und unsupervised learning.
% Auf diese wird nur weiter eingegangen, wenn zu wenig Text für eine positive Note für die Diplomarbeit vorliegen sollte.

\subsection{Künstliche Intelligenz allgemein [H]}
Künstliche Intelligenz funktioniert im Grunde genommen wie das menschliche Gehirn. Es basiert genauso auf Neuronen und deren Axonen, Dendriten und Terminale. Obwohl es verschiedene Arten von Neuronen gibt, haben sie alle gemeinsam, dass sie einen elektrischen Impuls als Reaktion auf einen Input aussenden. Abhängig von diesem Input ist durch das Neuron, welches das chemische Signal verarbeitet, der Output.

\begin{figure}[H]
    \centering
    \includegraphics[scale=1]{pics/Neuron.png}
    \caption{Neuron}
    \label{fig:tech:Neuron}
\end{figure}

Genauso funktioniert auch ein Neuronales Netz. Auf eine Eingabe folgt über eine Verarbeitung der Eingabe eine Ausgabe. Und genau wie bei einem Menschen, welcher etwas Neues kennenlernt, weiß auch das Neuronale Netz nicht, was dies Korrekte Antwort auf ein Problem ist. Es muss sich also herantasten an die Lösung.

\begin{figure}[H]
    \centering
    \includegraphics[scale=1]{pics/eba.png}
    \caption{Eingabe $\rightarrow$ Berechnung $\rightarrow$ Ausgabe}
    \label{fig:tech:eba}
\end{figure}

Ein einfaches mathematisches Beispiel hierfür wäre, wenn man einen einfachen Faktor mit zwei Nachkommastellen herausfinden möchte. Beispiel: Euro in USD umrechnen. Hierfür ist ein Faktor kleiner 1 nötig. Bevor der ganze Prozess des lernens startet, muss man mit einer Eingabe starten. Dies ist zum Beispiel die Zahl 1. Somit erkläre ich der künstlichen Intelligenz im übertragenen Sinne: ``Bitte errechne mir wie viele USD in meiner Hand liegen.''. Es wurde also ein Input für die KI gefunden. Dieser Input wird über eine nicht ganz zufällig gewählte Gewichtung in eine Berechnung umgewandelt. Nehmen wir an, diese Gewichtung sei ein Faktor <1 also 0,99. ``Nicht ganz zufällig gewählt'', weil der Anwender, welcher die KI schreibt im Vorhinein schon wusste, dass ein USD weniger Wert ist, als ein Euro; der genaue Wert war jedoch unbekannt. Nach dieser Berechnung kommt ein Wert raus – nämlich 0.99 – welcher falsch ist. Damit die künstliche Intelligenz jedoch weiß, ob sie richtig oder falsch rechnet, muss man ihr ein Feedback geben. Das heißt, dass der errechnete Wert und die Abweichung vom tatsächlichen Ergebnis (wenn dieses bekannt ist) zurückgegeben wird. In den meisten Fällen ist das Ergebnis bei präparierten Daten bereits bekannt, da diese als Trainingsdaten agieren. Wenn die künstliche Intelligenz jedoch selbst Entscheidungen vorhersagen muss, muss diese bereits mit solchen Daten trainiert worden sein, um ein akkurates Ergebnis liefern zu können. In dieser Phase lernt sie jedoch auch nicht mehr dazu. Sind die Ergebnisse unbekannt kann zum Beispiel das zuvor erklärte Reinforcement Learning als Lernstrategie herangezogen werden. Diese Abweichung wird nun mit einer weiteren Berechnung rückpropagiert und die Gewichte werden aktualisiert. Dieses Prozedere (Eingabe $\rightarrow$ Berechnung $\rightarrow$ Ausgabe $\rightarrow$ Fehler $\rightarrow$ Fehler rückpropagieren $\rightarrow$ Gewichte anpassen) wird so oft mit weiteren Trainingsdaten wiederholt, bis die KI einen minimalen Fehler (Differenz zwischen dem tatsächlichen Ergebnis und der Vorhersage) erreicht.
Allerdings können hier einige Faktoren zusätzliche beeinflusst werden, bevor die KI tatsächlich zu lernen beginnt, um ein maximal genaues Ergebnis zu erzielen. Beispielsweise beträgt der Wechselkurs von Euro zu USD 0,89. Als ein USD ist nur 0,89 so viel wert wie ein Euro. Wenn man es der KI ermöglicht sich nur in zehntel-Schritte an die Lösung anzupassen, so passiert folgendes:
Die KI wird das tatsächliche Ergebnis von 0,89 nie erreichen. Die von der KI errechnete Lösung beträgt entweder 0,9 oder 0,8. Wenn man diesen Anpassungswert jedoch kleiner ansetzt, auf ein Hundertstel zum Beispiel, so wird diese den Wert zwar langsamer erreichen, jedoch wird er genau dem Ziel entsprechen.
Dieser Wert darf jedoch auch nie zu klein gewählt werden. Schaut man sich dies an einem etwas komplexeren Beispiel an, so ist klar zu erkennen, dass in der folgenden Kurve der tatsächliche minimale Fehler nie erreicht wird. Um dies zu vermeiden, gibt es verschiedene Methoden. Als Exempel kann eine Art Fehler-Abtastungs-Beschleunigung herangezogen werden. Hier wird der Faktor, um welchen die Abweichung korrigiert wird in einer Art Beschleunigung angepasst. Man muss sich also den Aktuellen wert wie einen Ball vorstellen, welcher über einen Berg hinunterrollt.

\begin{figure}[H]
    \centering
    \includegraphics[scale=1]{pics/fehler.png}
    \caption{Fehlerkurve}
    \label{fig:tech:Fehler}
\end{figure}

Durch das Momentum kann der Ball nachfolgende Hindernisse überwinden. Die Gefahr dabei besteht jedoch, dass wenn der Ball nicht noch einmal angeschubst wird in einem höheren Tal zum Stehen kommt, weil das Momentum zum Zurückkommen fehlt. Es kann aber auch sein, dass der Ball nie genug Momentum hatte, da er zu wenig stark losbewegt wurde. All das und VIELES mehr fällt unter dem Begriff ``Hyperparameter Tuning''. Es muss also schon zu Beginn, bevor das Neuronale Netz überhaupt zu lernen beginnt, darauf geachtet werden, dass die Parameter stimmen, damit das Ergebnis einer perfekten Lösung am ähnlichsten ist.
Auch bei der Auswahl der Trainingsdaten ist enorme Vorsicht geboten. So ist es in einem amerikanischen Experiment dazu gekommen, dass eine Künstliche Intelligenz, rassistisch wurde. Diese Software sollte Richtern dabei helfen Häftlinge nach ihrer Entlassung zu beurteilen, wie hoch die Wahrscheinlichkeit sei, dass diese eine Wiederholungsstraftat begehen. Dabei kam heraus, dass dunkel-häutige Menschen weitaus gefährlicher eingestuft wurden als alle anderen. Das passierte, nicht weil diese tatsächlich eine höhere Gefahr darstellen, sondern weil in den USA dunkel-häutige Menschen öfter verhaftet werden. So stimmten auch die Probationen in den für die KI vorliegenden Trainingsdatensätzen nicht. Daraufhin meinte ein beteiligter Journalist: „Künstliche Intelligenz hat keine Meinung oder ein Bewusstsein, sondern handelt nach dem, was wir ihr vorgeben. Diese Daten und Informationen sind oft ein Spiegel der Gesellschaft und reproduzieren so auch Vorurteile, zum Beispiel durch Über- und Unterrepräsentation“.
Zitat \textbf{Tobias Matzner}
%https://www.rnd.de/wissen/wie-kuenstliche-intelligenz-rassismus-befoerdert-TZFL7KPOYRHFRBAA66OVOFS6QI.html%
\\
Und dass man mit Mathematik auch tatsächlich Spiele gewinnen kann, beziehungsweise, dass eine KI, welche immer wieder eine Gewichtung einer Eingabe aktualisiert, auch wirklich schlauer wird, wird im folgenden Beispiel erklärt. Hier geht es um ein Spiel in welchem man mit Mathematik eine Gewinnchance erhöht. Dies wird erzielt, indem man wiederholt Berechnungen ausführt und Gewichte aktualisiert. Somit wird die Gewinnchance in dem Spiel erhöht.
\\
Der Name des Spiels ist ``Hexapawn'' und wurde von Martin Gardner entwickelt, welcher im Zweiten Weltkrieg half den ``Nazicode'' zu knacken.
\\
Das Spiel ist wie folgt aufgebaut: ein 3x3 Schachbrett bildet den Untergrund des Spiels. Auf den jeweils gegenüberliegenden Seiten befinden sich 3 Schachfiguren. Deutlich wird dies in der nachfolgenden Abbildung.


\begin{figure}[H]
    \centering
    \includegraphics[scale=1]{pics/hexapawn/hexapawn_setup.png}
    \caption{Hexapawn Spielumgebung}
    \label{fig:tech:HexapawnSetup}
\end{figure}

Diese drei Figuren sind gleichwertig und dürfen sich Verhalten wie ein ``Bauer'' im Spiel Schach (also nur nach vor oder zum Schmeißen nach links und rechts). Martin Gardner setzt dabei die Regel fest, dass der Mensch, welche Seite er auch immer spielt, den ersten Zug macht. Somit ist der Mensch immer in den ungeraden Zügen dran (1, 3, 5, 7) und der Computer/die künstliche Intelligenz/die Mathematik immer in den geraden Zügen (2, 4, 6) dran. Nach acht Zügen gibt es garantiert immer einen Gewinner. Das Ziel des Spiels ist es, dass man alle gegnerischen Figuren schmeißt.
\\
Um einen solchen ``Hexapawn''-Computer zu bauen braucht man vierundzwanzig Streichholzschachteln. Auf jedem dieser Streichholzschachteln sind alle möglichen ``Hexapawn''-Züge aufgezeichnet, und wie auf diese reagiert werden kann. Dies wird in der nachstehenden Grafik veranschaulicht. Seitlich haben diese Schachteln eine Öffnung.


\begin{figure}[H]
    \centering
    \includegraphics[scale=1]{pics/hexapawn/hexapawn_zuege.jpg}
    \caption{Hexapawn mögliche Züge}
    \label{fig:tech:HexapawnZuege}
\end{figure}


Wähle ich als Mensch und Gegner der Maschine meinen ersten Zug, so ist dieser garantiert auf einen der beiden ersten Abbildungen zu sehen. In den Zündholzschachteln befinden sich farbige Kugeln. Schüttelt man diese nun, und lässt eine Kugel aus der Öffnung seitlich fallen, so wählt man den Zug, bei welchem die Pfeilfarbe der Kugelfarbe entspricht. So spielt man das Spiel zu ende, bis es nach dem achten Zug einen garantierten Gewinner gibt und zieht dann ein Resultat. Das heißt, wenn die KI gewonnen hat, kann man die Gewinnchance bei einem nächsten Spiel erhöhen. Dies erreicht man, indem man alle farbigen Kugeln, welche aus der Streichholzschachtel fielen, doppelt zurücklegt. Wenn es also in der ersten Schachtel grün, rot und blau gibt und grün als erster Zug eines Spiels gewählt wurde, welches zu einem Sieg führte, so gibt man in die erste Schachtel eine zweite grüne Kugel. Somit wird die Wahrscheinlichkeit, dass man bei einem nächsten Spiel einen Zug wählt, welcher schon einmal zu einem Sieg führte, erhöht. Ähnlich kann man dies auch bei Zügen machen, welche dazu führten, das Spiel zu verlieren. Hier kann man die Wahrscheinlichkeit zu verlieren verringern, indem man die Farbige Kugel aus dem Spiel entnimmt.
\\
Und so hat Martin Gardner bewiesen, dass man Spiele mit Mathematik gewinnen kann. Auf diesem Prinzip basieren auch viele andere künstliche Intelligenzen. Natürlich können in dem Spiel ``Hexapawn'' binnen weniger Augenblicke alle möglichen Kombinationen errechnet werden und somit eine perfekte Spielstrategie entwickelt werden. Anders ist dies bei Spielen wie ``Schach'' oder ``GO''. Bei diesen Spielen gibt es unzählige Kombinationsmöglichkeiten, bei welchen es selbst für eine Maschine nahezu unmöglich ist, alle Spielkombinationen auszuprobieren. Jedoch ist es für einen Computer möglich in kürzester Zeit extrem viele Berechnungen durchzuführen. Ein tage-/monate-/jahrelanges lernen in einer Geschwindigkeit, welche für Menschen unantastbar ist, führt für die KI also auch zu einer immer höheren Gewinnchance für jedes Spiel. Dadurch ist es für die sogenannte ``AlphaGo''-KI möglich gewesen selbst die besten Spieler der Welt im Spiel ``GO'' zu besiegen. Durch die vielen Kombinationsmöglichkeiten ist es trotzdem nicht gegeben, dass die KI pro Zug die perfekte Auswahl trifft. Jedoch werden immer Züge gewählt, welche in bisherigen Spielen zu der höchsten Gewinnchance führten. Somit ist es also auch für eine Maschine möglich nicht deterministische Ereignisse mit einer gewissen Wahrscheinlichkeit, welche oft der realen Zukunft entspricht, vorherzusagen (Beispiel: Wettervorhersage).

